import asyncio
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup
import pandas as pd
import re
from datetime import datetime

# ‡∏Å‡∏≠‡∏á‡∏ó‡∏∏‡∏ô‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢
TEST_TICKER = "LU0385659072:EUR"

async def scrape_regions_smart():
    print(f"üöÄ STARTING PLAYWRIGHT (SMART WAIT)...")
    print(f"üéØ Target: {TEST_TICKER}")
    
    url = f"https://markets.ft.com/data/funds/tearsheet/holdings?s={TEST_TICKER}"
    
    async with async_playwright() as p:
        # ‡πÄ‡∏õ‡∏¥‡∏î Browser (Headless = True ‡∏Ñ‡∏∑‡∏≠‡πÑ‡∏°‡πà‡πÇ‡∏ä‡∏ß‡πå‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠)
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()
        
        try:
            # 1. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö
            print("1Ô∏è‚É£ Loading Page...")
            await page.goto(url, timeout=60000)
            
            # 2. ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏õ‡∏∏‡πà‡∏° Regions (‡πÉ‡∏ä‡πâ Selector ‡∏ó‡∏µ‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)
            print("2Ô∏è‚É£ Clicking 'Regions' Tab...")
            # ‡πÉ‡∏ä‡πâ force=True ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏Å‡∏î‡πÅ‡∏°‡πâ‡∏à‡∏∞‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡∏±‡∏á
            await page.click('li[aria-controls="regions-panel"]', force=True)
            
            # 3. üî• SMART WAIT: ‡∏£‡∏≠‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏à‡∏≠‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ Region/Market/Country ‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á
            print("3Ô∏è‚É£ Waiting for 'Regions' Data to appear...")
            
            # Selector ‡∏ô‡∏µ‡πâ‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡πà‡∏≤: ‡∏´‡∏≤ <th> ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ Region ‡∏´‡∏£‡∏∑‡∏≠ Market ‡∏´‡∏£‡∏∑‡∏≠ Country ‡∏≠‡∏¢‡∏π‡πà‡∏Ç‡πâ‡∏≤‡∏á‡πÉ‡∏ô
            # ‡∏ö‡∏≠‡∏ó‡∏à‡∏∞‡∏£‡∏≠‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 15 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏≤‡∏à‡∏∞ Error (‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤‡πÑ‡∏î‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏¥‡∏î)
            try:
                await page.wait_for_selector(
                    '#regions-panel th:has-text("Region"), #regions-panel th:has-text("Market"), #regions-panel th:has-text("Country")', 
                    state='visible', 
                    timeout=15000
                )
            except Exception:
                print("‚ö†Ô∏è Warning: Wait timed out. Data might not be available or slow.")
            
            # 4. ‡∏î‡∏∂‡∏á HTML
            # ‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Å‡∏•‡πà‡∏≠‡∏á Regions ‡∏°‡∏≤‡πÄ‡∏•‡∏¢
            content_html = await page.inner_html('#regions-panel')
            print("‚úÖ Data Loaded! Parsing...")
            
            # --- PARSING ---
            soup = BeautifulSoup(content_html, 'lxml')
            data = []
            
            tables = soup.find_all('table')
            for table in tables:
                headers = [th.text.strip().lower() for th in table.find_all('th')]
                print(f"   üîé Found Headers: {headers}")
                
                # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏≠‡∏µ‡∏Å‡∏£‡∏≠‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏ß‡∏£‡πå
                if any(k in headers for k in ['region', 'market', 'country']):
                    print("   üéâ JACKPOT! Found Regions Table.")
                    
                    idx_net = -1
                    idx_cat = -1
                    for i, h in enumerate(headers):
                        if 'net assets' in h: idx_net = i
                        if 'category' in h: idx_cat = i
                    
                    if idx_net != -1:
                        rows = table.find_all('tr')
                        for row in rows:
                            cols = row.find_all('td')
                            if len(cols) > idx_net:
                                name = cols[0].text.strip()
                                val = cols[idx_net].text.strip()
                                print(f"      - {name}: {val}")
                                data.append({'name': name, 'value': val})
                    break 
            
            if not data:
                print("‚ùå No Region data extracted (Table might be empty or structure changed).")

        except Exception as e:
            print(f"‚ùå Error: {e}")
        finally:
            await browser.close()
            print("üèÅ Browser Closed.")

if __name__ == "__main__":
    asyncio.run(scrape_regions_smart())