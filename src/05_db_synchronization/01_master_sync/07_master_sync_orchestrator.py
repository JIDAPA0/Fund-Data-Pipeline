import subprocess
import sys
import time
import os
from pathlib import Path

# ==========================================
# 1. SETUP ROOT PATH
# ==========================================
BASE_DIR = Path(__file__).resolve().parent.parent.parent.parent
sys.path.append(str(BASE_DIR))

from src.utils.logger import setup_logger, log_execution_summary

# ‚úÖ Logger Name
logger = setup_logger("05_sync_Orchestrator")

# ==========================================
# 2. DEFINE PIPELINES
# ==========================================

# ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà 1: Scrapers (‡∏à‡∏∞‡∏™‡∏±‡πà‡∏á‡∏£‡∏±‡∏ô‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô‡πÅ‡∏ö‡∏ö Parallel)
SCRAPER_GROUP = [
    {"name": "FT List Scraper",      "path": "src/01_master_list_acquisition/01_ft_list_scraper.py"},
    {"name": "YF List Scraper",      "path": "src/01_master_list_acquisition/02_yf_list_scraper.py"},
    {"name": "SA List Scraper",      "path": "src/01_master_list_acquisition/03_sa_list_scraper.py"},
]

# ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà 2: ETL Pipeline (‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏±‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö Sequential)
ETL_PIPELINE = [
    {"name": "00 Data Cleaner",         "path": "src/05_db_synchronization/01_master_sync/00_master_list_cleaner.py"},
    {"name": "01 Source Consolidator",  "path": "src/05_db_synchronization/01_master_sync/01_source_consolidator.py"},
    {"name": "02 Data Validator",       "path": "src/05_db_synchronization/01_master_sync/02_master_list_validator.py"},
    {"name": "03 Data Remediator",      "path": "src/05_db_synchronization/01_master_sync/03_master_list_remediator.py"},
    {"name": "04 Database Loader",      "path": "src/05_db_synchronization/01_master_sync/04_master_list_loader.py"},
    {"name": "05 Status Manager",       "path": "src/05_db_synchronization/01_master_sync/05_status_manager.py"},
    {"name": "06 Data Archiver",        "path": "src/05_db_synchronization/01_master_sync/06_master_data_archiver.py"}
]

# ==========================================
# 3. HELPER FUNCTIONS
# ==========================================

def get_env():
    env = os.environ.copy()
    env["PYTHONPATH"] = str(BASE_DIR)
    return env

def run_scrapers_in_parallel():
    """‡∏£‡∏±‡∏ô Scraper ‡∏ó‡∏∏‡∏Å‡∏ï‡∏±‡∏ß‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô ‡πÅ‡∏•‡∏∞‡∏£‡∏≠‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏™‡∏£‡πá‡∏à‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
    logger.info(f"‚ö° STARTING PHASE 1: Scrapers (Parallel Mode - {len(SCRAPER_GROUP)} tasks)")
    
    processes = []
    
    # 1. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏±‡∏ô‡∏ó‡∏∏‡∏Å‡∏ï‡∏±‡∏ß‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô (Fire and Forget)
    for script in SCRAPER_GROUP:
        full_path = BASE_DIR / script["path"]
        if not full_path.exists():
            logger.error(f"‚ùå Script Not Found: {full_path}")
            continue
            
        logger.info(f"   ‚ñ∂Ô∏è  Launching: {script['name']}...")
        
        # Popen ‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏∏‡∏ç‡πÅ‡∏à‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ô‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏£‡∏≠ (Non-blocking)
        try:
            p = subprocess.Popen(
                [sys.executable, str(full_path)],
                env=get_env(),
                # stdout=subprocess.DEVNULL, # ‡∏õ‡∏¥‡∏î Log ‡∏•‡∏π‡∏Å‡∏ô‡πâ‡∏≠‡∏á‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏£‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡∏´‡∏•‡∏±‡∏Å (‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏î‡πâ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏´‡πá‡∏ô)
                # stderr=subprocess.PIPE
            )
            processes.append({"name": script["name"], "process": p})
        except Exception as e:
            logger.error(f"‚ùå Failed to launch {script['name']}: {e}")

    # 2. ‡∏£‡∏≠‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏ó‡∏∏‡∏Å‡∏ï‡∏±‡∏ß‡∏à‡∏∞‡πÄ‡∏™‡∏£‡πá‡∏à (Wait)
    logger.info("‚è≥ Waiting for all scrapers to finish...")
    success_count = 0
    
    for item in processes:
        p = item["process"]
        name = item["name"]
        
        # ‡∏£‡∏≠‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ
        return_code = p.wait()
        
        if return_code == 0:
            logger.info(f"   ‚úÖ Finished: {name}")
            success_count += 1
        else:
            logger.warning(f"   ‚ö†Ô∏è Failed: {name} (Return Code: {return_code})")
            
    return success_count

def run_etl_sequentially():
    """‡∏£‡∏±‡∏ô ETL ‡∏ó‡∏µ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö"""
    logger.info(f"üîÑ STARTING PHASE 2: ETL Pipeline (Sequential Mode)")
    
    for script in ETL_PIPELINE:
        name = script["name"]
        full_path = BASE_DIR / script["path"]
        
        if not full_path.exists():
            logger.error(f"‚ùå Script Not Found: {full_path}")
            return False

        logger.info(f"   ‚ñ∂Ô∏è  Executing: {name}...")
        start = time.time()
        
        try:
            # ‡πÉ‡∏ä‡πâ run ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏à‡∏ö‡∏Å‡πà‡∏≠‡∏ô‡πÑ‡∏õ‡∏ï‡∏±‡∏ß‡∏ñ‡∏±‡∏î‡πÑ‡∏õ (Blocking)
            subprocess.run([sys.executable, str(full_path)], check=True, env=get_env())
            logger.info(f"   ‚úÖ Success: {name} ({round(time.time() - start, 2)}s)")
        except subprocess.CalledProcessError:
            logger.critical(f"üõë CRITICAL ERROR: {name} failed. Aborting Pipeline.")
            return False
            
    return True

# ==========================================
# 4. MAIN ORCHESTRATOR
# ==========================================
def main():
    total_start = time.time()
    logger.info("üöÄ MASTER SYNC ORCHESTRATOR STARTED")
    
    # --- PHASE 1: ACQUISITION ---
    scrapers_success = run_scrapers_in_parallel()
    
    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ Scraper ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏ö‡πâ‡∏≤‡∏á‡πÑ‡∏´‡∏° (‡∏ñ‡πâ‡∏≤‡∏û‡∏±‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏•‡∏¢ ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡∏ó‡∏≥ ETL ‡∏ï‡πà‡∏≠ ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏ï‡πà‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢)
    if scrapers_success == 0:
        logger.warning("‚ö†Ô∏è All scrapers failed or none ran. Proceeding to ETL with existing data (if any).")
    
    logger.info("-" * 50)
    
    # --- PHASE 2: SYNCHRONIZATION ---
    etl_success = run_etl_sequentially()
    
    status = "Success" if etl_success else "Failed"
    
    log_execution_summary(
        logger, 
        total_start, 
        total_items=0, 
        status=status,
        extra_info={
            "Scrapers OK": f"{scrapers_success}/{len(SCRAPER_GROUP)}",
            "ETL Status": "Completed" if etl_success else "Aborted"
        }
    )

if __name__ == "__main__":
    main()